# ğŸ¸ Guitar-villAIn

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg)](https://opencv.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Personal research project exploring two independent approaches to automate key presses in Guitar Hero-like games using Computer Vision and, experimentally, Reinforcement Learning. The goal is to learn and experiment with real-time vision and system design.

## ğŸ¯ Independent approaches

### 1) Color/Polygon Approach (`color_pattern_approach/`)
- **Idea**: Detect notes by HSV color inside lane polygons and simulate key presses.
- **Tech**: OpenCV, NumPy, MSS/PyAutoGUI, pydirectinput.
- **Design**: Dedicated capture thread, per-lane processing, anti-spam input logic.

### 2) Reinforcement Learning Approach (`reinforcement_ai_approach/`)
- **Idea**: A DQN agent learns to play from vision-based observations.
- **Tech**: Gymnasium, PyTorch (DQN/Dueling/Double), OpenCV.
- **Design**: `GuitarHeroEnv` environment, `DQNAgent` agent, threaded capture, combo/score OCR.

Both approaches are **completely independent** and represent different learning paths for the same problem.

## âœ¨ Key technologies

This project explores:

- **Vision**: OpenCV (HSV, morphology, contours, polygon masking).
- **Input**: `pydirectinput` to simulate keys on Windows.
- **Capture**: `mss` (preferred) and `pyautogui` (fallback) in a dedicated thread.
- **RL**: PyTorch, Gymnasium, DQN/Dueling/Double, Prioritized Replay (experimental).
- **OCR**: Tesseract via `pytesseract` for combo/score (RL approach).

## ğŸ› ï¸ Project structure

```
Guitar-villAIn/
â”œâ”€â”€ ğŸ“‚ color_pattern_approach/          # Approach de detecciÃ³n por color
â”‚   â”œâ”€â”€ color_pattern_visualizer.py
â”‚   â”œâ”€â”€ screen_capture.py
â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ config.ini
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ“‚ reinforcement_ai_approach/       # Approach de Reinforcement Learning
â”‚   â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ dqn_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ env.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ screen_capture.py
â”‚   â”‚   â”‚   â”œâ”€â”€ score_detector.py
â”‚   â”‚   â”‚   â””â”€â”€ combo_detector.py
â”‚   â”‚   â””â”€â”€ ğŸ“‚ utils/
â”‚   â”‚       â”œâ”€â”€ config_manager.py
â”‚   â”‚       â”œâ”€â”€ helpers.py
â”‚   â”‚       â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”‚   â”œâ”€â”€ polygon_visualizer.py
â”‚   â”‚   â”œâ”€â”€ setup_wizard.py
â”‚   â”‚   â””â”€â”€ static_hsv_calibrator_plus.py
â”‚   â”œâ”€â”€ ğŸ“‚ config/
â”‚   â”‚   â””â”€â”€ config.ini
â”‚   â”œâ”€â”€ input_preview.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ğŸ”§ launch_*.py                     # Scripts launcher
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Dependencias principales
â”œâ”€â”€ ğŸ“‚ logs/                          # Logs del sistema
â””â”€â”€ ğŸ“– README.md                      # DocumentaciÃ³n
```

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos
- Python 3.11+
- Windows 10/11 (requiere privilegios de administrador para simular teclas)
- Guitar Hero ejecutÃ¡ndose en modo ventana

### InstalaciÃ³n RÃ¡pida
```powershell
# Desde la raÃ­z del proyecto
pip install -r requirements.txt
```

### Ejecutar

**Configurar Regiones de Captura:**
```bash
python launch_setup_wizard.py
```

**Color/Polygon Approach:**
```bash
python launch_color_pattern.py
```

**Reinforcement Learning Approach:**
```bash
python launch_input_preview.py
python reinforcement_ai_approach/train.py
```

### Scripts Launcher
Los launchers permiten ejecutar desde cualquier directorio:
- `launch_setup_wizard.py` - ConfiguraciÃ³n visual de regiones
- `launch_input_preview.py` - Preview del approach de RL
- `launch_color_pattern.py` - Visualizer del approach de color

## ğŸ§­ Process diagrams

### Color/Polygon (a.k.a. Sloth) approach â€“ per frame
```mermaid
flowchart TD
    A[MSS thread capture] -->|latest frame| B[Main loop]
    B --> C[Prepare per-lane tasks]
    C --> D{ThreadPoolExecutor}
    D --> E1[Lane S: crop microimage -> HSV -> morphology -> contours]
    D --> E2[Lane D]
    D --> E3[Lane F]
    D --> E4[Lane J]
    D --> E5[Lane K]
    D --> E6[Lane L]
    E1 --> F[Filter by polygon and area]
    E2 --> F
    E3 --> F
    E4 --> F
    E5 --> F
    E6 --> F
    F --> G[Aggregate detections]
    G --> H[Input logic: green/yellow + anti-spam]
    H --> I[Visual overlay & HUD]
    I --> J[Next frame]
```

Notes:
- Each lane is processed independently in parallel.
- For green notes, yellow processing can be skipped within the same lane.
- Input logic applies cooldowns and controlled randomness.

### Reinforcement Learning approach â€“ per step
```mermaid
graph TD
    A[env.step] --> B[Apply action]
    B --> C[Get latest frame]
    C --> D[HSV masks + polygons]
    D --> E[OCR combo/score]
    E --> F[Compute reward]
    F --> G[Return obs/reward/done]
    G --> H[DQN agent]
```

## ğŸ“‚ Project Structure

```
Guitar-villAIn/
â”œâ”€â”€ color_pattern_approach/          # Computer Vision Research
â”‚   â”œâ”€â”€ color_pattern_visualizer.py  # Main detection experiment
â”‚   â”œâ”€â”€ config_manager.py           # Configuration system
â”‚   â”œâ”€â”€ screen_capture.py           # Optimized capture system
â”‚   â”œâ”€â”€ config.ini                  # Experiment parameters
â”‚   â”œâ”€â”€ requirements.txt            # Dependencies
â”‚   â””â”€â”€ README.md                   # Research documentation
â”‚
â”œâ”€â”€ reinforcement_ai_approach/       # AI Research
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ dqn_agent.py        # Deep Q-Network implementation
â”‚   â”‚   â”‚   â””â”€â”€ env.py              # Gymnasium environment
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ combo_detector.py   # OCR-based combo detection
â”‚   â”‚   â”‚   â”œâ”€â”€ score_detector.py   # Score detection system
â”‚   â”‚   â”‚   â””â”€â”€ screen_capture.py   # Screen capture for AI
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ config_manager.py   # Configuration management
â”‚   â”‚       â”œâ”€â”€ helpers.py          # Utility functions
â”‚   â”‚       â””â”€â”€ logger.py           # Logging system
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ polygon_visualizer.py   # Detection visualization
â”‚   â”‚   â””â”€â”€ static_hsv_calibrator_plus.py # HSV calibration
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.ini              # AI experiment parameters
â”‚   â”œâ”€â”€ train.py                    # Training experiment
â”‚   â”œâ”€â”€ combo_calibrator.py         # Calibration tool
â”‚   â”œâ”€â”€ requirements.txt            # AI dependencies
â”‚   â””â”€â”€ README.md                   # AI research documentation
â”‚
â”œâ”€â”€ lanzar_color_pattern.bat        # Quick start script
â””â”€â”€ README.md                       # This overview
```

## ğŸ”§ Configuration
- Each approach has its own `config.ini` defining capture, lane polygons, HSV ranges and auxiliary parameters.
- The RL approach additionally defines agent hyperparameters and OCR regions.

## ğŸ› ï¸ Herramientas

**Scripts Launcher (Ejecutar desde cualquier directorio):**
- `launch_setup_wizard.py` - ConfiguraciÃ³n visual de regiones de captura
- `launch_input_preview.py` - Preview del approach de Reinforcement Learning
- `launch_color_pattern.py` - Visualizer del approach de Color Pattern

**Herramientas de Debug:**
- `polygon_visualizer.py` - Visualizar polÃ­gonos de detecciÃ³n
- `static_hsv_calibrator_plus.py` - Calibrar rangos HSV
- `combo_calibrator.py` - Calibrar detecciÃ³n de combos

## ğŸ§ª Inicio RÃ¡pido

**ConfiguraciÃ³n Inicial (Obligatorio):**
```bash
python launch_setup_wizard.py
```

**Color/Polygon Approach:**
```bash
python launch_color_pattern.py
```

**Reinforcement Learning (Experimental):**
```bash
python launch_input_preview.py  # Para visualizar con OCR de score
python reinforcement_ai_approach/train.py  # Para entrenar
```

**Herramientas Adicionales:**
```bash
python reinforcement_ai_approach/utils/polygon_visualizer.py
python reinforcement_ai_approach/utils/static_hsv_calibrator_plus.py
```

## âœ¨ CaracterÃ­sticas Especiales

### ğŸ” **OCR Mejorado del Score**
- **MÃºltiples mÃ©todos de thresholding** para mejor detecciÃ³n
- **Diferentes modos PSM de Tesseract** para mayor precisiÃ³n
- **VisualizaciÃ³n en tiempo real** de la regiÃ³n del score
- **Thumbnail de debugging** para ver el procesamiento OCR
- **DetecciÃ³n robusta** de nÃºmeros con mÃºltiples estrategias

### ğŸ¯ **VisualizaciÃ³n Avanzada**
- **Cajas delimitadoras** para todas las regiones detectadas
- **InformaciÃ³n de debug** en tiempo real
- **Estado del OCR** con indicadores visuales
- **Vista previa del procesamiento** de imÃ¡genes

## ğŸ“· Screenshots
Place images in `assets/screenshots/`. Example usage in docs:

```markdown
![P5X rhythm minigame](assets/screenshots/p5x_rhythm_example.png)
```

## ğŸ§  Future work
- Color approach: better morphology heuristics and per-lane segmentation.
- RL approach: stabilize training and improve observation/reward design.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenCV community
- PyTorch team
- Guitar Hero community

---

**ğŸ¸ Personal project of Computer Vision and AI applied to rhythm games.**